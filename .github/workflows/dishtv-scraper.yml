name: Daily TV Schedule Scrape

on:
  workflow_dispatch:      # Allows you to click a button to run it manually
  schedule:
    - cron: '0 2 * * *'   # Runs automatically every day at 2:00 AM UTC (7:30 AM IST)

# Grants permission to read/write files to the repository
permissions:
  contents: write

jobs:
  scrape-and-save:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout the repository content
      - name: Checkout Code
        uses: actions/checkout@v3

      # 2. Setup Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 3. Install dependencies (Your script only needs requests)
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # 4. Run your Python Script
      - name: Run Scraper
        run: |
          python dishtv_multi_scrape.py

      # 5. Commit and Push changes (JSONs and Logs)
      - name: Commit and Push Results
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          
          # Add the JSON folders and any new log files
          git add today/ tomorrow/ *.log
          
          # Commit only if there are changes. 
          # "|| exit 0" prevents the workflow from failing if there are no changes.
          git commit -m "Update schedule and logs: $(date)" || exit 0
          
          git push
