name: Daily TV Schedule Scrape

on:
  workflow_dispatch:      # Allows manual trigger from GitHub Actions tab
  schedule:
    - cron: '0 2 * * *'   # Runs automatically every day at 2:00 AM UTC

permissions:
  contents: write         # Important: allows the action to push changes back to the repo

jobs:
  scrape-and-save:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout the repository
      - name: Checkout Code
        uses: actions/checkout@v3

      # 2. Setup Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 3. Install dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # 4. Run the Scraper Script
      - name: Run Scraper
        run: |
          python dishtv_multi_scrape.py

      # 5. Commit and Push changes
      - name: Commit and Push Results
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          
          # Stage the JSON folders and the specific static log file
          git add today/ tomorrow/ scrape_log.log
          
          # Commit only if there are changes (prevents error if nothing changed)
          git commit -m "Update schedule and logs: $(date)" || exit 0
          
          git push
